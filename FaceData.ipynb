{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# creating a haar-cascade object for face detection\n",
    "face_cas = cv2.CascadeClassifier('./haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "# instantiate a camera object to capture images\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# for storing the data\n",
    "data = []\n",
    "ix = 0 # current frame number\n",
    "while True:\n",
    "    # retrieve the check (boolean) and frame from camera\n",
    "    check, frame = video.read()\n",
    "    \n",
    "    # if the camera is working fine, we proceed to extract the face\n",
    "    if check == True:\n",
    "        # converting the current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Here in order to detect faces in the current frame , we'll use Haar Cascade which is a \n",
    "        # classifier to detect faces in the image frame. Also , 1.3 and 5 are fine tuning\n",
    "        #parameters\n",
    "        faces = face_cas.detectMultiScale(gray, 1.3, 5)\n",
    "        # for each face object we get, we have\n",
    "        # the corner coords (x, y)\n",
    "        # and the width and height of the face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # getting the face component from the image frame\n",
    "            component_of_face = frame[y:y+h, x:x+w, :]\n",
    "            # resize the face image to 50X50X3\n",
    "            # NOTE: Resizing is necessary so that recognisor can work on equally sized images\n",
    "            fc = cv2.resize(component_of_face, (50, 50))\n",
    "            # Since we want to store after every 10 frames that's why ix%10 is required . Also we want\n",
    "            # the length of our data to  be less than 20\n",
    "            if ix%10 == 0 and len(data) < 20:\n",
    "                data.append(fc)\n",
    "                # for visualization, draw a rectangle around the face\n",
    "                # in the image\n",
    "            # Here , (x , y) represent the bottm-left corner coordinates , (x+w , y+h) represent top-right\n",
    "            # corner coordinates , (255,255,0) represents the color of the rectangle drawn around the face\n",
    "            # and 2 represents the thickness of the box( NOTE: putting -1 as thickness will draw an opaque\n",
    "            # rectangle around the face)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "        \n",
    "        ix += 1 # increment the current frame number\n",
    "        cv2.imshow('frame', frame) # display the frame\n",
    "                # if the user presses the character 'q'\n",
    "                # or the number of images hits 20, we stop\n",
    "                # recording.\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q') or len(data) >= 20:\n",
    "            break\n",
    "            \n",
    "# now we destroy the windows we have created\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "# converting the data to a numpy format\n",
    "data = np.asarray(data)\n",
    "\n",
    "# print the shape\n",
    "print (data.shape)\n",
    "\n",
    "# saving the data as a numpy matrix in an encoded format\n",
    "np.save('face_01', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
